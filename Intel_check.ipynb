{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35085bda-1838-4b14-8cbc-d472f61ba59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13fff192-9a42-4581-a495-1214d5e3078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to training and testing data\n",
    "train_data_path = '/Users/raghavgarg/Downloads/archive (1)/seg_train/seg_train/'\n",
    "test_data_path = '/Users/raghavgarg/Downloads/archive (1)/seg_test/seg_test/'\n",
    "\n",
    "# Output directories for models and reports\n",
    "output_dir = '/Users/raghavgarg/Downloads'\n",
    "models_dir = os.path.join(output_dir, \"models\")\n",
    "reports_dir = os.path.join(output_dir, \"reports\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(reports_dir, exist_ok=True)\n",
    "classes = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03fe2171-3667-4a3c-b09b-03d61f3409f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "Class with minimum images: buildings (2191 images)\n",
      "Class with maximum images: mountain (2512 images)\n",
      "Total images: 14034\n",
      "\n",
      "Validation Dataset:\n",
      "Class with minimum images: buildings (437 images)\n",
      "Class with maximum images: glacier (553 images)\n",
      "Total images: 3000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_dataset_stats(directory):\n",
    "    class_counts = {}\n",
    "    total_images = 0  # Initialize total image counter\n",
    "\n",
    "    # Loop through each class folder in the directory\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):  # Check if it's a folder\n",
    "            image_count = len(os.listdir(class_path))  # Count files in the folder\n",
    "            class_counts[class_name] = image_count\n",
    "            total_images += image_count  # Add to the total count\n",
    "\n",
    "    # Get the class with min and max images\n",
    "    min_class = min(class_counts, key=class_counts.get)\n",
    "    max_class = max(class_counts, key=class_counts.get)\n",
    "\n",
    "    return {\n",
    "        \"min\": (min_class, class_counts[min_class]),\n",
    "        \"max\": (max_class, class_counts[max_class]),\n",
    "        \"total\": total_images\n",
    "    }\n",
    "\n",
    "# Paths to train and validation directories\n",
    "train_dir = '/Users/raghavgarg/Downloads/archive (1)/seg_train/seg_train/'\n",
    "validation_dir = '/Users/raghavgarg/Downloads/archive (1)/seg_test/seg_test/'\n",
    "\n",
    "# Get stats for training and validation datasets\n",
    "train_stats = get_dataset_stats(train_dir)\n",
    "validation_stats = get_dataset_stats(validation_dir)\n",
    "\n",
    "# Print results\n",
    "print(\"Training Dataset:\")\n",
    "print(f\"Class with minimum images: {train_stats['min'][0]} ({train_stats['min'][1]} images)\")\n",
    "print(f\"Class with maximum images: {train_stats['max'][0]} ({train_stats['max'][1]} images)\")\n",
    "print(f\"Total images: {train_stats['total']}\")\n",
    "\n",
    "print(\"\\nValidation Dataset:\")\n",
    "print(f\"Class with minimum images: {validation_stats['min'][0]} ({validation_stats['min'][1]} images)\")\n",
    "print(f\"Class with maximum images: {validation_stats['max'][0]} ({validation_stats['max'][1]} images)\")\n",
    "print(f\"Total images: {validation_stats['total']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d110dcb-e1d1-4efa-b0ac-8e32efea6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set data augmentation techniques\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,vertical_flip=True\n",
    "                                                             ,zoom_range=0.2,rotation_range=360\n",
    "                                                             ,width_shift_range=0.1,height_shift_range=0.1\n",
    "                                                             ,channel_shift_range=50\n",
    "                                                             ,brightness_range=(0,1.2)\n",
    "                                                             ,preprocessing_function=keras.applications.imagenet_utils.preprocess_input)\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.imagenet_utils.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "248ba7b3-4cc5-428b-9a19-50d716b08bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading images directly from directories\n",
    "batch_size = 70\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b984a3-c428-4247-9e6c-9dff42e271eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics will be logged to: /Users/raghavgarg/Downloads/metrics_log.csv\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "\n",
    "# Helper function to calculate F1 Score, Sensitivity, and Specificity\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precisions, recalls, f1_scores, specificities = [], [], [], []\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        tp = cm[i, i]\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        tn = cm.sum() - (tp + fn + fp)\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "        specificities.append(specificity)\n",
    "\n",
    "    return {\n",
    "        'f1_score': np.mean(f1_scores),\n",
    "        'sensitivity': np.mean(recalls),\n",
    "        'specificity': np.mean(specificities)\n",
    "    }\n",
    "\n",
    "# Custom callback to save metrics and checkpoints\n",
    "class SaveMetricsAndCheckpoints(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, log_file_path='/kaggle/working/metrics_log.csv', save_interval=10):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.log_file_path = log_file_path\n",
    "        self.save_interval = save_interval\n",
    "\n",
    "        # Initialize the CSV file with headers\n",
    "        with open(self.log_file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                'epoch',\n",
    "                'train_loss', 'train_accuracy', 'train_precision', 'train_recall', \n",
    "                'train_top_1_accuracy', 'train_top_5_accuracy',\n",
    "                'val_loss', 'val_accuracy', 'val_precision', 'val_recall',\n",
    "                'val_top_1_accuracy', 'val_top_5_accuracy',\n",
    "                'f1_score', 'sensitivity', 'specificity'\n",
    "            ])\n",
    "        print(f\"Metrics will be logged to: {self.log_file_path}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Extract validation data\n",
    "        val_images, val_labels = self.validation_data\n",
    "        y_pred = self.model.predict(val_images)\n",
    "        y_pred_labels = tf.argmax(y_pred, axis=1).numpy()\n",
    "        y_true_labels = tf.argmax(val_labels, axis=1).numpy()\n",
    "\n",
    "        # Calculate additional metrics\n",
    "        additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "        # Save metrics to the CSV file\n",
    "        with open(self.log_file_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                epoch + 1,\n",
    "                logs.get('loss'), logs.get('accuracy'), logs.get('precision'), logs.get('recall'),\n",
    "                logs.get('top_1_accuracy'), logs.get('top_5_accuracy'),\n",
    "                logs.get('val_loss'), logs.get('val_accuracy'), logs.get('val_precision'), logs.get('val_recall'),\n",
    "                logs.get('val_top_1_accuracy'), logs.get('val_top_5_accuracy'),\n",
    "                additional_metrics['f1_score'], additional_metrics['sensitivity'], additional_metrics['specificity']\n",
    "            ])\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}: Metrics logged.\")\n",
    "\n",
    "        # Save model checkpoint every nth epoch\n",
    "        if (epoch + 1) % self.save_interval == 0:\n",
    "            checkpoint_filepath = (\n",
    "                f\"/kaggle/working/model-\"\n",
    "                f\"{epoch + 1:02d}-\"\n",
    "                f\"val_acc_{logs['val_accuracy']:.4f}.keras\"\n",
    "            )\n",
    "            self.model.save(checkpoint_filepath)\n",
    "            print(f\"Model checkpoint saved at: {checkpoint_filepath}\")\n",
    "\n",
    "# Validation data\n",
    "validation_data = next(iter(validation_generator))\n",
    "\n",
    "# Initialize callback\n",
    "metrics_and_checkpoint_callback = SaveMetricsAndCheckpoints(\n",
    "    validation_data=(validation_data[0], validation_data[1]),\n",
    "    log_file_path='/Users/raghavgarg/Downloads/metrics_log.csv',\n",
    "    save_interval=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bfe401-b80e-4111-8532-11f3d9aa8cb1",
   "metadata": {},
   "source": [
    "## DENSE_AVG_DEPTH_CONST_224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89ff7e68-6cc6-411e-975d-e243ae29d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/DENSENET169/AVG_DEPTH_224/DENSE_AVG_DEPTH_CONST_224.h5\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/DENSENET169/AVG_DEPTH_224/DENSE_AVG_DEPTH_CONST_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18489853-396a-44ef-94b1-4992116141df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12669510"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c02e7b-e8fd-4ed8-8d78-37cf7eea53a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.8705 - loss: 0.4487 - precision: 0.8774 - recall: 0.8662 - top_1_accuracy: 0.8705 - top_5_accuracy: 0.9986\n",
      "Test Loss: 0.4567815065383911\n",
      "Test Accuracy: 0.8733333349227905\n",
      "Test Precision: 0.8797703385353088\n",
      "Test Recall: 0.8683333396911621\n",
      "Top-1 Accuracy: 0.8733333349227905\n",
      "Top-5 Accuracy: 0.9986666440963745\n",
      "F1 Score: 0.8734334733158223\n",
      "Sensitivity (Recall): 0.8743028322880056\n",
      "Specificity: 0.9746166329444694\n"
     ]
    }
   ],
   "source": [
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca31fc33-c9e5-4502-9ac7-647af873af48",
   "metadata": {},
   "source": [
    "## DENSE_DEPTH_CONST_224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd5e5bfe-a66f-4dc6-a8b6-779e9e0dc81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12736070"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/DENSENET169/DEPTH_224/dense_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecb1dc77-3c1c-4db6-8436-914ef86b1e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/DENSENET169/DEPTH_224/dense_depth_224.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.8788 - loss: 0.4579 - precision: 0.8816 - recall: 0.8755 - top_1_accuracy: 0.8788 - top_5_accuracy: 0.9998\n",
      "Test Loss: 0.47070300579071045\n",
      "Test Accuracy: 0.8773333430290222\n",
      "Test Precision: 0.8815213441848755\n",
      "Test Recall: 0.8730000257492065\n",
      "Top-1 Accuracy: 0.8773333430290222\n",
      "Top-5 Accuracy: 0.9993333220481873\n",
      "F1 Score: 0.8777040645410156\n",
      "Sensitivity (Recall): 0.8785256702681083\n",
      "Specificity: 0.975419281599922\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/DENSENET169/DEPTH_224/dense_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27093b09-724e-4d90-b7d4-b9f0bd723d02",
   "metadata": {},
   "source": [
    "## DENSE GAP 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9fbdc5d-6385-40ef-b135-b397a4c7b28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12652870"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/DENSENET169/GAP 224/DENSENET224GAP.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "831ccad3-c366-4ce8-b6f0-cb63cf10d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/DENSENET169/GAP 224/DENSENET224GAP.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.8310 - loss: 0.6586 - precision: 0.8505 - recall: 0.8228 - top_1_accuracy: 0.8310 - top_5_accuracy: 0.9986\n",
      "Test Loss: 0.5717562437057495\n",
      "Test Accuracy: 0.8450000286102295\n",
      "Test Precision: 0.8619979619979858\n",
      "Test Recall: 0.8370000123977661\n",
      "Top-1 Accuracy: 0.8450000286102295\n",
      "Top-5 Accuracy: 0.9980000257492065\n",
      "F1 Score: 0.8449678160517546\n",
      "Sensitivity (Recall): 0.8453046843125006\n",
      "Specificity: 0.9689796285968605\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/DENSENET169/GAP 224/DENSENET224GAP.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62052993-3c1c-4ea3-be84-596d6f61f2c5",
   "metadata": {},
   "source": [
    "## EFFICIENT AVG DEPTH 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82a7efc3-bc36-4c58-8850-787b6d81370d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4070057"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/EFFICIENTNETB0/AVG_DEPTH_224/effi_avg_depth_224.keras'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "514baaf6-f4bd-4a8b-9ab2-14816cd57f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/EFFICIENTNETB0/AVG_DEPTH_224/effi_avg_depth_224.keras\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734685024.939443 1938576 service.cc:148] XLA service 0x600003d9cb00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734685024.939953 1938576 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "2024-12-20 14:27:05.036927: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1734685025.681473 1938576 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 5s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 5s/step - accuracy: 0.8689 - loss: 0.3671 - precision: 0.8793 - recall: 0.8635 - top_1_accuracy: 0.8689 - top_5_accuracy: 0.9998\n",
      "Test Loss: 0.3455387353897095\n",
      "Test Accuracy: 0.8830000162124634\n",
      "Test Precision: 0.8911794424057007\n",
      "Test Recall: 0.8790000081062317\n",
      "Top-1 Accuracy: 0.8830000162124634\n",
      "Top-5 Accuracy: 0.999666690826416\n",
      "F1 Score: 0.8830475749804169\n",
      "Sensitivity (Recall): 0.8839436870538849\n",
      "Specificity: 0.9765564883237273\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/EFFICIENTNETB0/AVG_DEPTH_224/effi_avg_depth_224.keras'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819ad2d-dcdd-496c-aef8-15e3be8f0504",
   "metadata": {},
   "source": [
    "## EFFICIENT DEPTH 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e4d4313-5d75-4c58-8d7e-ea9c245422a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4121257"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/EFFICIENTNETB0/DEPTH_224/effi_dense_224.keras'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "644eb523-4a66-44f8-81c8-c6dcfa223041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/EFFICIENTNETB0/DEPTH_224/effi_dense_224.keras\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 5s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 5s/step - accuracy: 0.8837 - loss: 0.3544 - precision: 0.8886 - recall: 0.8783 - top_1_accuracy: 0.8837 - top_5_accuracy: 0.9996\n",
      "Test Loss: 0.34710028767585754\n",
      "Test Accuracy: 0.887333333492279\n",
      "Test Precision: 0.8941494822502136\n",
      "Test Recall: 0.8813333511352539\n",
      "Top-1 Accuracy: 0.887333333492279\n",
      "Top-5 Accuracy: 0.9993333220481873\n",
      "F1 Score: 0.888180867336754\n",
      "Sensitivity (Recall): 0.888961393579772\n",
      "Specificity: 0.9773959066233836\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/EFFICIENTNETB0/DEPTH_224/effi_dense_224.keras'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47354d73-9f33-42bc-8f46-fd6cfa803dc4",
   "metadata": {},
   "source": [
    "## EFFICIENT GAP 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68e7cc72-11b1-4a86-a72a-81491be82baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4057257"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/EFFICIENTNETB0/GAP_224/effi_gap_224.keras'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd9b9207-8d1c-428b-9a78-68b73415afc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/EFFICIENTNETB0/GAP_224/effi_gap_224.keras\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 5s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 5s/step - accuracy: 0.8683 - loss: 0.3736 - precision: 0.8760 - recall: 0.8602 - top_1_accuracy: 0.8683 - top_5_accuracy: 0.9995\n",
      "Test Loss: 0.35532158613204956\n",
      "Test Accuracy: 0.8790000081062317\n",
      "Test Precision: 0.885840117931366\n",
      "Test Recall: 0.871666669845581\n",
      "Top-1 Accuracy: 0.8790000081062317\n",
      "Top-5 Accuracy: 0.9993333220481873\n",
      "F1 Score: 0.8792846858421606\n",
      "Sensitivity (Recall): 0.8801301148403716\n",
      "Specificity: 0.9757383716917203\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/EFFICIENTNETB0/GAP_224/effi_gap_224.keras'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ed2ca-ea3e-470c-bb35-78c58758d2d4",
   "metadata": {},
   "source": [
    "## MOBILENETV2 AVG DENSE 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2781fd7-c284-49d5-a339-184e9e891049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2278470"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/MOBILENETV2/AVG_DEPTH_224/mobile_avg_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95fd3f5d-a7b8-4e58-a03f-aba0e1cef5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/MOBILENETV2/AVG_DEPTH_224/mobile_avg_depth_224.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 468ms/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 453ms/step - accuracy: 0.8746 - loss: 0.3589 - precision: 0.8786 - recall: 0.8711 - top_1_accuracy: 0.8746 - top_5_accuracy: 0.9998\n",
      "Test Loss: 0.36707186698913574\n",
      "Test Accuracy: 0.8823333382606506\n",
      "Test Precision: 0.8883265852928162\n",
      "Test Recall: 0.8776666522026062\n",
      "Top-1 Accuracy: 0.8823333382606506\n",
      "Top-5 Accuracy: 0.999666690826416\n",
      "F1 Score: 0.8827716040581975\n",
      "Sensitivity (Recall): 0.8836673709481602\n",
      "Specificity: 0.9763854837114273\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/MOBILENETV2/AVG_DEPTH_224/mobile_avg_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f212c-5296-48eb-8285-2eb59d99d10a",
   "metadata": {},
   "source": [
    "## MOBILE DENSE 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1c70775-ef61-417e-bfee-c4656ad4ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2329670"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/MOBILENETV2/DEPTH_224/mobile_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93775638-cf0d-4681-98e4-63f66d9c8726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/MOBILENETV2/DEPTH_224/mobile_depth_224.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 450ms/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 445ms/step - accuracy: 0.8982 - loss: 0.3089 - precision: 0.9049 - recall: 0.8943 - top_1_accuracy: 0.8982 - top_5_accuracy: 0.9998\n",
      "Test Loss: 0.3144559860229492\n",
      "Test Accuracy: 0.8999999761581421\n",
      "Test Precision: 0.9068511724472046\n",
      "Test Recall: 0.8956666588783264\n",
      "Top-1 Accuracy: 0.8999999761581421\n",
      "Top-5 Accuracy: 0.999666690826416\n",
      "F1 Score: 0.9006155259312997\n",
      "Sensitivity (Recall): 0.9014277321834894\n",
      "Specificity: 0.9799509206684859\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/MOBILENETV2/DEPTH_224/mobile_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee9125-ddb7-4c32-83b4-d9eec596e741",
   "metadata": {},
   "source": [
    "## MOBILE GAP 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2b9135e-57cf-47e1-883b-21adb49f355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2265670"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/MOBILENETV2/GAP_224/MobileNetV2_GAP_220.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a72a2dde-dafc-497c-a3ae-e260d3f29ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/MOBILENETV2/GAP_224/MobileNetV2_GAP_220.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 478ms/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 456ms/step - accuracy: 0.8801 - loss: 0.3804 - precision: 0.8865 - recall: 0.8772 - top_1_accuracy: 0.8801 - top_5_accuracy: 0.9993\n",
      "Test Loss: 0.3723303973674774\n",
      "Test Accuracy: 0.8886666893959045\n",
      "Test Precision: 0.8954821228981018\n",
      "Test Recall: 0.8853333592414856\n",
      "Top-1 Accuracy: 0.8886666893959045\n",
      "Top-5 Accuracy: 0.9986666440963745\n",
      "F1 Score: 0.8888566293414365\n",
      "Sensitivity (Recall): 0.8897412509854107\n",
      "Specificity: 0.9776948314471542\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/MOBILENETV2/GAP_224/MobileNetV2_GAP_220.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a614ad-b80a-4568-80b0-eccb770a8e5d",
   "metadata": {},
   "source": [
    "## RESNET AVG DEPTH 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53da45a1-734c-4764-9fe1-2e0af9674ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23620486"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/RESNET50/AVG_DEPTH_224/resnet_avg_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78eb04a8-d917-42ec-bb7c-88faa7ca81c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/RESNET50/AVG_DEPTH_224/resnet_avg_depth_224.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.8676 - loss: 0.4520 - precision: 0.8739 - recall: 0.8640 - top_1_accuracy: 0.8676 - top_5_accuracy: 0.9994\n",
      "Test Loss: 0.4346264600753784\n",
      "Test Accuracy: 0.8730000257492065\n",
      "Test Precision: 0.8785834908485413\n",
      "Test Recall: 0.8683333396911621\n",
      "Top-1 Accuracy: 0.8730000257492065\n",
      "Top-5 Accuracy: 0.9990000128746033\n",
      "F1 Score: 0.8729978936652358\n",
      "Sensitivity (Recall): 0.8738152274895196\n",
      "Specificity: 0.9745747462377571\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/RESNET50/AVG_DEPTH_224/resnet_avg_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ab15a-064e-46a5-9846-f1464ab29a3f",
   "metadata": {},
   "source": [
    "## RESNET DEPTH 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bc19dc1-5d2b-4436-a8a8-713e01424579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23702406"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/RESNET50/DEPTH_224/resnet_depthwise_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1ffc60e-9dd6-43db-a120-e9ff81239e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/RESNET50/DEPTH_224/resnet_depthwise_224.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.8658 - loss: 0.4924 - precision: 0.8739 - recall: 0.8594 - top_1_accuracy: 0.8658 - top_5_accuracy: 0.9988\n",
      "Test Loss: 0.5101150870323181\n",
      "Test Accuracy: 0.856333315372467\n",
      "Test Precision: 0.8629441857337952\n",
      "Test Recall: 0.8500000238418579\n",
      "Top-1 Accuracy: 0.856333315372467\n",
      "Top-5 Accuracy: 0.9980000257492065\n",
      "F1 Score: 0.8563241874225612\n",
      "Sensitivity (Recall): 0.8576067608985362\n",
      "Specificity: 0.9712597361816885\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/RESNET50/DEPTH_224/resnet_depthwise_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359d845-efbb-4e69-a6fc-17ec6075514b",
   "metadata": {},
   "source": [
    "## RESNET GAP 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "608466a4-95e4-4396-856f-8428e2436a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23600006"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/RESNET50/GAP_224/RESNET50_GAP_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b859b9f-6560-4820-85cc-ca61a720bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/RESNET50/GAP_224/RESNET50_GAP_224.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8326 - loss: 0.5738 - precision: 0.8421 - recall: 0.8226 - top_1_accuracy: 0.8326 - top_5_accuracy: 0.9986\n",
      "Test Loss: 0.6232506632804871\n",
      "Test Accuracy: 0.8489999771118164\n",
      "Test Precision: 0.8608636260032654\n",
      "Test Recall: 0.8373333215713501\n",
      "Top-1 Accuracy: 0.8489999771118164\n",
      "Top-5 Accuracy: 0.9973333477973938\n",
      "F1 Score: 0.8483424102065027\n",
      "Sensitivity (Recall): 0.8492219209714795\n",
      "Specificity: 0.9697404433853292\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/RESNET50/GAP_224/RESNET50_GAP_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4dba5a-a5c9-45ed-9c19-ae3370683a7d",
   "metadata": {},
   "source": [
    "## XCEPTION AVG DENSE 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da2f6d0a-dc10-4731-b4f8-b01e42bc0013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20894254"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/XCEPTIONNET/AVG_DEPTH_224/xcep_avg_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31e6d242-8ef2-4896-a34c-b58fbccd38b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/XCEPTIONNET/AVG_DEPTH_224/xcep_avg_depth_224.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3s/step - accuracy: 0.9012 - loss: 0.4541 - precision: 0.9054 - recall: 0.9005 - top_1_accuracy: 0.9012 - top_5_accuracy: 0.9991\n",
      "Test Loss: 0.4949043393135071\n",
      "Test Accuracy: 0.8939999938011169\n",
      "Test Precision: 0.8959866166114807\n",
      "Test Recall: 0.8930000066757202\n",
      "Top-1 Accuracy: 0.8939999938011169\n",
      "Top-5 Accuracy: 0.9986666440963745\n",
      "F1 Score: 0.8949080702977912\n",
      "Sensitivity (Recall): 0.8958142865918859\n",
      "Specificity: 0.9787375796839252\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/XCEPTIONNET/AVG_DEPTH_224/xcep_avg_depth_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae97a10-ff83-47f7-ad66-f8280e91a4dc",
   "metadata": {},
   "source": [
    "## XCEPTION DENSE 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4314378-b8cf-42d8-b776-83e8cd7ffcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20976174"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/XCEPTIONNET/DEPTH_224/XCEP_DEPTH_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d787f4d-a62e-46d3-960b-dedeaeb78c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/XCEPTIONNET/DEPTH_224/XCEP_DEPTH_224.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - accuracy: 0.8932 - loss: 0.5009 - precision: 0.8953 - recall: 0.8930 - top_1_accuracy: 0.8932 - top_5_accuracy: 0.9992\n",
      "Test Loss: 0.49575650691986084\n",
      "Test Accuracy: 0.893666684627533\n",
      "Test Precision: 0.8957219123840332\n",
      "Test Recall: 0.8933333158493042\n",
      "Top-1 Accuracy: 0.893666684627533\n",
      "Top-5 Accuracy: 0.9990000128746033\n",
      "F1 Score: 0.8944645386044646\n",
      "Sensitivity (Recall): 0.8948481026623324\n",
      "Specificity: 0.9786765892262567\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/XCEPTIONNET/DEPTH_224/XCEP_DEPTH_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab1d87-a311-4327-a219-26b94f462701",
   "metadata": {},
   "source": [
    "## XCEPTION GAP 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "975aa88e-b370-4425-9474-003c71987255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20873774"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/XCEPTIONNET/GAP_224/Xcep_GAP_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1b398d2-1715-4b1a-9c8f-551a060dabef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /Users/raghavgarg/Downloads/RESEARCH/XCEPTIONNET/GAP_224/Xcep_GAP_224.h5\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 3s/step - accuracy: 0.8778 - loss: 0.5826 - precision: 0.8789 - recall: 0.8750 - top_1_accuracy: 0.8778 - top_5_accuracy: 0.9991\n",
      "Test Loss: 0.6819871664047241\n",
      "Test Accuracy: 0.862666666507721\n",
      "Test Precision: 0.8649916052818298\n",
      "Test Recall: 0.8606666922569275\n",
      "Top-1 Accuracy: 0.862666666507721\n",
      "Top-5 Accuracy: 0.9990000128746033\n",
      "F1 Score: 0.8630366849190936\n",
      "Sensitivity (Recall): 0.8650028955305196\n",
      "Specificity: 0.9725696263140943\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved checkpoint\n",
    "model_path = '/Users/raghavgarg/Downloads/RESEARCH/XCEPTIONNET/GAP_224/Xcep_GAP_224.h5'  # Update the model path as needed\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded from: {model_path}\")\n",
    "# Test Data Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Ground truth labels from the test generator\n",
    "y_true_labels = test_generator.classes\n",
    "\n",
    "# Calculate additional metrics like precision, recall, F1 score, etc.\n",
    "additional_metrics = calculate_metrics(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Evaluate the model on test data to get Top-1 and Top-5 accuracy\n",
    "test_loss, test_accuracy, test_precision, test_recall, top_1_acc, top_5_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Top-1 Accuracy: {top_1_acc}\")\n",
    "print(f\"Top-5 Accuracy: {top_5_acc}\")\n",
    "print(f\"F1 Score: {additional_metrics['f1_score']}\")\n",
    "print(f\"Sensitivity (Recall): {additional_metrics['sensitivity']}\")\n",
    "print(f\"Specificity: {additional_metrics['specificity']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
